{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LlZlyv6_nx6"
   },
   "source": [
    "# Image Histograms\n",
    "\n",
    "Goal of the lecture:\n",
    "\n",
    "1. Load the RGB region from the previous lectures\n",
    "2. Convert the data from the original `uint16` type to the `uint8` range\n",
    "3. Calculate the histogram of each individual band\n",
    "4. Apply a \"Modified Contrast Adjustment\"\n",
    "5. Apply histogram equalization\n",
    "6. Generate a mask image and visualize overlayed image\n",
    "\n",
    "\n",
    "## Data loading\n",
    "\n",
    "Short recap:\n",
    "- In the previous lecture we downloaded an S2 tile.\n",
    "- The data values themselves were not touched!\n",
    "    - That means that the data-type is `uint16`.\n",
    "    - The selected region had no `NO_DATA` values (these are encoded with the value `0`)\n",
    "        - No need to apply masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some code from that last labs\n",
    "\n",
    "# Provided template to download file; not relevant for course\n",
    "import requests\n",
    "from tqdm.rich import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def download_file_with_progress(url: str, output_file: Path):\n",
    "    \"\"\"\n",
    "    Given a `url` as a String and an `output_file` as a file-path the item will\n",
    "    be downloaded and written to the `output_file`. If the `output_file` already\n",
    "    exists, it will be overwritten.\n",
    "    \"\"\"\n",
    "    s = requests.Session()\n",
    "    chunk_size = 2**20  # mb\n",
    "    with s.get(url, stream=True) as resp:\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            print(f\"Saving to {output_file}\")\n",
    "            for data in tqdm(\n",
    "                resp.iter_content(chunk_size=chunk_size), \n",
    "                total=int(resp.headers.get(\"content-length\", 0)) // chunk_size, \n",
    "                unit=\"MB\",\n",
    "                unit_scale=True,\n",
    "                desc=\"Downloading...\",\n",
    "            ):\n",
    "                f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = Path(\"./data\")\n",
    "data_path.mkdir(exist_ok=True)\n",
    "# For quick prototyping there is no such things as _too many_ asserts!\n",
    "assert data_path.exists, \"Should exist after calling mkdir!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tile_name = Path(\"S2A_MSIL2A_20240308T100841_N0510_R022_T33UUU_20240308T143352\")\n",
    "output_filepath = data_path / tile_name.with_suffix(\".SAFE.zip\")\n",
    "output_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# re-hosted file on TUB-Cloud for fast download during class ~1GB before and 1GB after unpacking\n",
    "sentinel_tile_url = \"https://tubcloud.tu-berlin.de/s/2EMnZwypF2pK5XG/download/S2A_MSIL2A_20240308T100841_N0510_R022_T33UUU_20240308T143352.SAFE.zip\"\n",
    "\n",
    "if not output_filepath.exists():\n",
    "    download_file_with_progress(sentinel_tile_url, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zipf = zipfile.ZipFile(output_filepath)\n",
    "zipf.extractall(path=\"data\")\n",
    "unzipped_dir = Path(data_path / tile_name.with_suffix(\".SAFE\"))\n",
    "assert unzipped_dir.exists(), f\"{unzipped_dir} does not exist!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def read_s2_jp2_data_with_clipping(\n",
    "    band_data_path: Path, clip_geoseries: geopandas.GeoSeries, envelope: bool = True\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given the `band_data_path` to a JP2000 encoded GeoTIFF file, return those parts that are overlapping with the\n",
    "    `clip_geoseries` GeoSeries. By default, the bounding box (`envelope`) of the geometry will be used to define the\n",
    "    region of interest.\n",
    "    \"\"\"\n",
    "    # open the GeoTIFF file which also contains the CRS metadata\n",
    "    with rasterio.open(band_data_path) as data:\n",
    "        # ensure that the data is using the same coordinate reference system and reproject if they don't\n",
    "        reprojected_geoseries = clip_geoseries.to_crs(data.crs)\n",
    "        # use the bounding box if `envelope` is set => Make sure that the matrix we get back can contain\n",
    "        # only valid values\n",
    "        reprojected_geoseries = (\n",
    "            reprojected_geoseries.envelope if envelope else reprojected_geoseries\n",
    "        )\n",
    "        # Use crop to only return the matrix that contains our region of interest\n",
    "        # Use `all_touched=True` to make sure that the border is also conisdered \"inside\" the region of interest\n",
    "        out_img, _out_transform = rasterio.mask.mask(\n",
    "            data, reprojected_geoseries, crop=True, all_touched=True\n",
    "        )\n",
    "        # drop singleton axes\n",
    "        out_img = out_img.squeeze()\n",
    "    return out_img\n",
    "\n",
    "class S2TileReader:\n",
    "    def __init__(self, directory: Path):\n",
    "        \"\"\"\n",
    "        Initialize the reader with a directory containing the SAFE file of a Sentinel-2 product.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory : Path\n",
    "            The directory containing the SAFE file of a Sentinel-2 product.\n",
    "        \"\"\"\n",
    "        assert directory.is_dir(), f\"{directory} is not a directory\"\n",
    "        self.image_files = list(directory.glob(f\"**/IMG_DATA/*.jp2\"))\n",
    "        if len(self.image_files) == 0:\n",
    "            self.image_files = list(directory.glob(f\"**/IMG_DATA/R60m/*.jp2\"))\n",
    "            self.image_files.extend(list(directory.glob(f\"**/IMG_DATA/R20m/*.jp2\")))\n",
    "            self.image_files.extend(list(directory.glob(f\"**/IMG_DATA/R10m/*.jp2\")))\n",
    "        self.band2file_mapping = self._bands()\n",
    "        self.bands = sorted(self.band2file_mapping.keys())\n",
    "        print(f\"{len(self.band2file_mapping)} images found in {directory}\")\n",
    "\n",
    "    def _bands(self):\n",
    "        \"\"\"\n",
    "        Extract the band names from the image files and create a mapping from band name to file path.\n",
    "\n",
    "        Example:\n",
    "        {\n",
    "            \"B01\": Path(\"path/to/B01.jp2\"),\n",
    "            \"B02\": Path(\"path/to/B02.jp2\"),\n",
    "            ...\n",
    "        }\n",
    "        or if the product has multiple resolutions:\n",
    "        {\n",
    "            \"B01_60m\": Path(\"path/to/R60m/B01.jp2\"),\n",
    "            \"B02_10m\": Path(\"path/to/R10m/B02.jp2\"),\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        return {\"_\".join(x.stem.split(\"_\")[2:]):x for x in self.image_files}\n",
    "\n",
    "    def read_band(self, band: str):\n",
    "        \"\"\"\n",
    "        Read the data of a specific band. The data is returned as a numpy array. If the band is a single channel,\n",
    "        the array will have shape (height, width). If the band is a multi-channel band, the array will have shape\n",
    "        (height, width, channels).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        band : str\n",
    "            The name of the band to read. Must be one of the bands in the product.\n",
    "            Use the `bands` attribute to see the available bands.\n",
    "        \"\"\"\n",
    "        assert band in self.bands, f\"Band {band} invalid. Please select one of {self.bands}\"\n",
    "        img_path = self.band2file_mapping[band]\n",
    "        with rasterio.open(self.band2file_mapping[band]) as f:\n",
    "            data = f.read()\n",
    "        if data.shape[0] == 1:\n",
    "            return data.squeeze(0)\n",
    "        elif data.shape[0] == 3:\n",
    "            return np.transpose(data, (1, 2, 0))\n",
    "\n",
    "    def read_band_data_with_clipping(\n",
    "        self, band: str, clip_geoseries: geopandas.GeoSeries, envelope: bool = True\n",
    "    ) -> np.ndarray:\n",
    "        assert band in self.bands, f\"Band {band} invalid. Please select one of {self.bands}\"\n",
    "        img_path = self.band2file_mapping[band]\n",
    "        return read_s2_jp2_data_with_clipping(img_path, clip_geoseries, envelope=envelope)\n",
    "\n",
    "\n",
    "s2_reader = S2TileReader(unzipped_dir)\n",
    "rgb_arr_full = np.stack(\n",
    "    [s2_reader.read_band(b) for b in (\"B04_10m\", \"B03_10m\", \"B02_10m\")],\n",
    "    axis=-1,\n",
    ")\n",
    "rgb_arr_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgb_arr = rgb_arr_full[-600:, -600:]\n",
    "# What is the shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "assert rgb_arr.shape == (600, 600, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert not (rgb_arr == 0).any(), \"There is an unexpected <NO_DATA> value!\"\n",
    "assert rgb_arr.dtype == np.uint16, \"The data is not in the original format anymore!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let us store the rgb_arr for the next lab as a npz file!\n",
    "np.savez(\n",
    "    \"data/rgb_arr\",\n",
    "    red=rgb_arr[:, :, 0],\n",
    "    green=rgb_arr[:, :, 1],\n",
    "    blue=rgb_arr[:, :, 2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to `uint8`\n",
    "\n",
    "For our following analysis we are would like the image to be in the `uint8` range [0, 255].\n",
    "To re-scale the data we have several options.\n",
    "We could apply a normalization strategy, like min-max-normalization or quantile normalization with rescaling, but we want to keep the data as close as possible to the _original_ data.\n",
    "\n",
    "To accomplish the re-scaling to `uint8`, we convert the data to the _reflectance_ value, according to the Sentinel-2 documentation.\n",
    "This will project the data to the range [0, 1]*.\n",
    "The formulae has _\"recently\"_ (January 2022) changed to:\n",
    "\n",
    "$$ \n",
    "\\text{reflectance}_i = \\frac{\\text{DN}_i + \\text{Offset}_i}{\\text{QuantificationValue}_i}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\text{QuantificationValue}_i$ = `10_000` for Sentinel-2 data\n",
    "    - Can be found in the `MTD_MSIL2A.xml` file under `BOA_QUANTIFICATION_VALUE`\n",
    "- $\\text{DN}_i$ is the digital number that is provided in the JPEG2000 files as a `uint16` value\n",
    "- $\\text{Offset}_i$ is the _newly_ introduced band-offset \n",
    "    - Can be found in the `MTD_MSIL2A.xml` file under `BOA_ADD_OFFSET`\n",
    "    - Often the same value for a given tile (for our tile it is `-1_000`)\n",
    "\n",
    "The details can be found on the [Copernicus Sentinel-2 product update page](https://scihub.copernicus.eu/news/News00931).\n",
    "For a more general overview of the Sentinel-2 L2A data, see the [Sentinelhub sentinel-L2A documentation](https://docs.sentinel-hub.com/api/latest/data/sentinel-2-l2a/).\n",
    "\n",
    "\n",
    "*) This is not entirely true; the reflectance value can become larger than 1. This is not important for our investigation and we will clamp the values to ensure that the range is actually [0, 1].\n",
    "\n",
    "### The rabbit hole\n",
    "As we have seen above, the Sentinel-2 data structure/format is not as easy to work with as other classic computer vision imagery.\n",
    "For our course it is sufficient to know how to derive the reflectance values from the source data.\n",
    "The details of the Sentinel-2 data format is a rabbit hole that is not relevant for the contents of the course.\n",
    "The key point is that the data cannot be nicely visualized without any image processing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Issues\n",
    "\n",
    "When working with `uintX` beware of [under-/overflow](https://en.wikipedia.org/wiki/Integer_overflow)!\n",
    "One _trick_ is to convert the source data into a different format.\n",
    "This may be done explicitely by calling `np.int64`, for example, or by adding/substracting float values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A_uint = np.array([0], dtype=np.uint8)\n",
    "A_uint - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A_int = np.array([0], dtype=np.int64)\n",
    "A_int - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.int64(A_uint) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A_uint - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# If unclear, provide more examples :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_float = (np.int64(rgb_arr) - 1_000) / 10_000\n",
    "img_float = np.clip(img_float, 0.0, 1.0)\n",
    "img = np.uint8(img_float * 255)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# change default figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (13, 13)\n",
    "\n",
    "\n",
    "def imshow(*args, **kwargs):\n",
    "    \"\"\"Short wrapper that calls `plt.imshow` with the provided arguments, but turns of the axis\"\"\"\n",
    "    plt.imshow(*args, **kwargs)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_i-3pjzFfaN"
   },
   "source": [
    "## Calculating histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What is the corect number of bins and the required `range` if we want to have a bin for each brightness value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "?np.histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "- We have values from 0 -- 255.\n",
    "- We want to count how often each individual value appears.\n",
    "- So we have 256 buckets (one for each number)\n",
    "- The left histogram edge is always inclusive\n",
    "    - 255 should be left histogram edge of the last bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print RGB histogram\n",
    "channel_names = [\"red\", \"green\", \"blue\"]\n",
    "\n",
    "for i, channel in enumerate(channel_names):\n",
    "    hist, bin_edges = np.histogram(img[:, :, i], bins=256, range=[0, 256])\n",
    "    assert bin_edges[0] == 0\n",
    "    assert bin_edges[-2] == 255\n",
    "    # 256 brightness values => 256 bins\n",
    "    assert len(hist) == 256\n",
    "    # using the fact that the channel names are also an accepted color name\n",
    "    plt.plot(hist, color=channel)\n",
    "    plt.xlabel(\"bin\")\n",
    "    plt.ylabel(\"No. of pixels\")\n",
    "    plt.title(\"Histograms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0mVg4KUhaOE"
   },
   "source": [
    "### Modified Contrast Adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture we have defined:\n",
    "\n",
    "$$\n",
    "I_\\text{out}[n, m] = \\begin{cases}\n",
    "    0, & \\text{if}\\ I_\\text{in}[m, n] < I_\\text{min}' \\\\\n",
    "    (2^L - 1) \\cdot \\frac{I_\\text{in}[m, n] - I_\\text{min}'}{I_\\text{max}' - I_\\text{min}'}, & \\text{if}\\ I_\\text{min}' \\leq I[m, n] \\leq I_\\text{max}' \\\\\n",
    "    2^L - 1, & \\text{if}\\ I_\\text{in}[n, m] > I_\\text{max}'\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $I_\\text{in}[n, m]$ is the input pixel value at the location $[n, m]$\n",
    "- $I_\\text{out}[n, m]$ is the output pixel value at the location $[n, m]$ after applying the modified contrast adjustment method\n",
    "- $I_\\text{min}'$ is the _selected_ minimum target value of the adjusted scale\n",
    "    - This does _not_ has to be minimum value of the target input image $I$\n",
    "- $I_\\text{max}'$ is the _selected_ maximum target value of the adjusted scale\n",
    "    - This does _not_ has to be maximum value of the target input image $I$\n",
    "- $L$ is the number of bits for the discrete brightness values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# implicitely convert by providing these values as float values\n",
    "fmin = 2.0\n",
    "fmax = 38.0\n",
    "\n",
    "adj_img = 255 * ((img - fmin) / (fmax - fmin))\n",
    "adj_img.min(), adj_img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adj_img = np.clip(adj_img, 0, 255)\n",
    "# convert it back to uint8\n",
    "adj_img = np.uint8(adj_img)\n",
    "# imshow(adj_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adj1 = 255 * ((img - fmin) / (fmax - fmin))\n",
    "adj1 = np.clip(adj_img, 0, 255)\n",
    "adj1 = np.uint8(adj_img)\n",
    "\n",
    "adj2 = np.clip(img, fmin, fmax)\n",
    "adj2 = 255 * ((adj2 - fmin) / (fmax - fmin))\n",
    "adj2 = np.uint8(adj2)\n",
    "\n",
    "(adj1 - adj2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "?np.clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, channel in enumerate(channel_names):\n",
    "    hist, bin_edges = np.histogram(adj_img[:, :, i], 256, range=[0, 256])\n",
    "    # hist, bin_edges = np.histogram(img[:, :, i], bins=np.arange(257))\n",
    "    assert bin_edges[0] == 0\n",
    "    assert bin_edges[-2] == 255\n",
    "    # 256 brightness values => 256 bins\n",
    "    assert len(hist) == 256\n",
    "    # using the fact that the channel names are also an accepted color name\n",
    "    plt.plot(hist, color=channel)\n",
    "    plt.xlabel(\"bin\")\n",
    "    plt.ylabel(\"No. of pixels\")\n",
    "    plt.title(\"Histograms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(adj_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_OqRruDWl7X"
   },
   "source": [
    "## Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_B = img[..., 2].copy()\n",
    "# disable implicit min/max normalization!\n",
    "imshow(img_B, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6nqFMqHlB5t"
   },
   "source": [
    "### In-course practice:\n",
    "\n",
    "- The formulae from the lecture originated from \"Remote Sensing Digital Image Analysis -- An Introduction 2013\" Ch. 4.4\n",
    "    - Refer to this chapter for the full derivation of the formulae that is used here\n",
    "\n",
    "$$ y' = \\text{constant} \\times C(x) = \\frac{L' - 1}{N} \\times C(x) = (L' - 1) \\cdot C_\\text{norm}(x)$$\n",
    "where:\n",
    "- $0 \\text{--} (L' - 1)$ are the $L$ brightness values available in the image\n",
    "    - These values do not _have_ to be present in the image\n",
    "    - For 8-bit images the $L' = 256$\n",
    "- $N$ is the total number of pixels in the image\n",
    "- $C(x)$ is the cumulative histogram function (hint: it can be calculated as a cumulative sum)\n",
    "\n",
    "The values $y'$ must then be converted to discrete integer values.\n",
    "We use the recommended approach of rounding to the nearest integer value.\n",
    "\n",
    "a ) plot the cumulative histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_B, hist_edges = np.histogram(img_B, 256, range=[0, 256])\n",
    "assert hist_edges[0] == 0\n",
    "assert hist_edges[-2] == 255\n",
    "assert len(hist_B) == 256\n",
    "cum_hist_B = hist_B.cumsum()\n",
    "plt.figure()\n",
    "plt.plot(cum_hist_B, color=\"r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTO4NeUYvqVL"
   },
   "source": [
    "b) calculate the equalized histogram \n",
    "<!-- START REMOVAL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_num_pixels = cum_hist_B.max()  # or c[-1]\n",
    "assert cum_hist_B.max() == cum_hist_B[-1]\n",
    "\n",
    "cdf_norm = cum_hist_B / total_num_pixels\n",
    "plt.plot(cdf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "L = 256\n",
    "y_prime = cdf_norm * (L - 1)\n",
    "y_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.round(y_prime, decimals=0)\n",
    "\n",
    "# y is our equalization function\n",
    "# note that maximum value is 255 and all values are integers\n",
    "# plot with bar to indicate that the values are discrete\n",
    "plt.bar(range(len(y)), y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert 0 <= y.min()\n",
    "assert y.max() <= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_B_eq = y[img_B]\n",
    "img_B_eq = np.uint8(img_B_eq)\n",
    "\n",
    "imshow(img_B_eq, vmin=0, vmax=255, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_B_eq, _ = np.histogram(img_B_eq, 256)\n",
    "c = hist_B_eq.cumsum()\n",
    "plt.bar(range(len(c)), c, width=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.bar(range(len(hist_B_eq)), hist_B_eq);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMWNEUI48clV"
   },
   "source": [
    "## Image Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "executionInfo": {
     "elapsed": 25630,
     "status": "ok",
     "timestamp": 1619775649435,
     "user": {
      "displayName": "Mat Rb",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gik24jvA_yZMp2z50oFh_gbhSlIRnt_v5WBVKY6REE=s64",
      "userId": "17685210069082378191"
     },
     "user_tz": -120
    },
    "id": "A7wQjHsWsztO",
    "outputId": "1bae1b52-a27a-45fa-b2eb-2be6bbadf03e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 120\n",
    "img_B_eq_thres = np.where(img_B_eq < threshold, 0, 255)\n",
    "\n",
    "imshow(img_B_eq_thres, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JoqUO4enqtyE"
   },
   "source": [
    "### In-course practice:\n",
    "Create a mask from the thresholded image and apply it on the original image and the contrast-adjusted image. \n",
    "The final image `img_masked` should be black in the masked out pixels and other pixels representing with their original values (colors).\n",
    "So values below the previous threshold should become 0 and the values equal/larger than the threshold should stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = f\"\"\"\n",
    "{img_B_eq_thres.shape=}\n",
    "{img.shape=}\n",
    "\"\"\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1935,
     "status": "ok",
     "timestamp": 1619775659013,
     "user": {
      "displayName": "Mat Rb",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gik24jvA_yZMp2z50oFh_gbhSlIRnt_v5WBVKY6REE=s64",
      "userId": "17685210069082378191"
     },
     "user_tz": -120
    },
    "id": "BCjcXtpntJ_q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "keep_indicator = img_B_eq_thres > 0\n",
    "keep_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "(keep_indicator == False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "keep_indicator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# use previously adjusted histogram image to display the values\n",
    "adj_img_masked = np.where(keep_indicator, adj_img, 0)\n",
    "imshow(adj_img_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(keep_indicator, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# use previously adjusted histogram image to display the values\n",
    "adj_img_masked = np.where(keep_indicator[..., np.newaxis], adj_img, 0)\n",
    "imshow(adj_img_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# use ellipses to create new axis at the last dimensionality\n",
    "# equal to img_B_eq_thres[:, :, np.newaxis]\n",
    "# https://numpy.org/doc/stable/glossary.html?highlight=ellipses#term-.-.-.\n",
    "img_masked = np.where(keep_indicator[..., np.newaxis], img, 0)\n",
    "imshow(img_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8u7dIbC-8Cy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab02.ipynb",
   "provenance": [
    {
     "file_id": "18HnQi1z1r9VdZMy5Znl5syklqPvNETKl",
     "timestamp": 1619767948261
    }
   ]
  },
  "interpreter": {
   "hash": "d950cc255805eca97bc9adaef38440cdd4d88c80fff2afb10853f0ffb81a073c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
